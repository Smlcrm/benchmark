{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7304c6ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'toto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtoto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaskedTimeseries\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtoto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecaster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TotoForecaster\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtoto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Toto\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'toto'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from toto.data.util.dataset import MaskedTimeseries\n",
    "from toto.inference.forecaster import TotoForecaster\n",
    "from toto.model.toto import Toto\n",
    "\n",
    "# These lines make gpu execution in CUDA deterministic\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)\n",
    "# Load the pre-trained model\n",
    "toto = Toto.from_pretrained('Datadog/Toto-Open-Base-1.0')\n",
    "toto.to('cuda')  # Move to GPU\n",
    "\n",
    "# Optionally compile the model for faster inference\n",
    "toto.compile()  # Uses Torch's JIT compilation for better performance\n",
    "\n",
    "forecaster = TotoForecaster(toto.model)\n",
    "\n",
    "# Prepare your input time series (channels, time_steps)\n",
    "input_series = torch.randn(7, 4096).to('cuda')  # Example with 7 variables and 4096 timesteps\n",
    "\n",
    "# Prepare timestamp information (optional, but expected by API; not used by the current model release)\n",
    "timestamp_seconds = torch.zeros(7, 4096).to('cuda')\n",
    "time_interval_seconds = torch.full((7,), 60*15).to('cuda')  # 15-minute intervals\n",
    "\n",
    "# Create a MaskedTimeseries object\n",
    "inputs = MaskedTimeseries(\n",
    "    series=input_series,\n",
    "    padding_mask=torch.full_like(input_series, True, dtype=torch.bool),\n",
    "    id_mask=torch.zeros_like(input_series),\n",
    "    timestamp_seconds=timestamp_seconds,\n",
    "    time_interval_seconds=time_interval_seconds,\n",
    ")\n",
    "\n",
    "# Generate forecasts for the next 336 timesteps\n",
    "forecast = forecaster.forecast(\n",
    "    inputs,\n",
    "    prediction_length=336,\n",
    "    num_samples=256,  # Number of samples for probabilistic forecasting\n",
    "    samples_per_batch=256,  # Control memory usage during inference\n",
    ")\n",
    "\n",
    "# Access results\n",
    "median_prediction = forecast.median  # Point forecasts\n",
    "prediction_samples = forecast.samples  # Probabilistic samples\n",
    "lower_quantile = forecast.quantile(0.1)  # 10th percentile for lower confidence bound\n",
    "upper_quantile = forecast.quantile(0.9)  # 90th percentile for upper confidence bound"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
